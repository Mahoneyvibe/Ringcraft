# Story 11.3: Voice Input Integration

## Status
Approved

## Story
**As a** club official,
**I want** to use voice input,
**So that** I can interact hands-free in busy gym environments.

## Acceptance Criteria
1. Tap-to-speak button on AI bar enables voice input
2. Uses browser-native Web Speech API (no external services)
3. Visual feedback during listening (pulsing indicator)
4. Transcribed text appears in input field for review before sending
5. Works on supported browsers (mobile and desktop)
6. Graceful degradation when speech recognition unavailable

## Dependencies
- **Story 11.2** (AI Bar - Text Input) — must be complete (provides AI bar, chat infrastructure)

## Tasks / Subtasks

- [ ] Task 1: Create speech recognition hook (AC: 2, 3, 6)
  - [ ] 1.1 Create `src/hooks/useSpeechRecognition.ts` wrapping Web Speech API
  - [ ] 1.2 Implement browser support detection (`window.SpeechRecognition` or `window.webkitSpeechRecognition`)
  - [ ] 1.3 Define TypeScript types for speech recognition state
  - [ ] 1.4 Handle speech recognition lifecycle: start, stop, abort
  - [ ] 1.5 Implement `onResult` handler to capture transcribed text
  - [ ] 1.6 Implement `onError` handler with error type mapping
  - [ ] 1.7 Configure recognition settings: `continuous: false`, `interimResults: true`, `lang: 'en-GB'`
  - [ ] 1.8 Return state object: `{ isListening, transcript, interimTranscript, error, isSupported, startListening, stopListening }`
  - [ ] 1.9 Add cleanup on unmount (abort any active recognition)

- [ ] Task 2: Create voice input button component (AC: 1, 3)
  - [ ] 2.1 Create `src/components/ai/VoiceInputButton.tsx`
  - [ ] 2.2 Implement idle state: mic icon (Lucide `mic`)
  - [ ] 2.3 Implement listening state: pulsing animated mic with "Listening..." tooltip
  - [ ] 2.4 Implement processing state: transcribing indicator (Lucide `mic` with loading)
  - [ ] 2.5 Implement error state: mic with X (Lucide `mic-off`) with retry option
  - [ ] 2.6 Implement unsupported state: disabled mic with tooltip "Voice input not supported on this browser"
  - [ ] 2.7 Apply pulsing animation using CSS keyframes with `--accent` color (#3B82F6)
  - [ ] 2.8 Honor `prefers-reduced-motion`: replace pulse with static highlight
  - [ ] 2.9 Ensure touch target is minimum 44x44px

- [ ] Task 3: Integrate voice input into AI Bar (AC: 1, 4)
  - [ ] 3.1 Update `src/components/layout/AIBar.tsx` to use `useSpeechRecognition` hook
  - [ ] 3.2 Replace disabled mic button with functional `VoiceInputButton`
  - [ ] 3.3 On voice result, populate input field with transcribed text (do NOT auto-submit)
  - [ ] 3.4 Show interim transcript in input field with visual differentiation (lighter opacity)
  - [ ] 3.5 User can edit transcribed text before submitting
  - [ ] 3.6 User can cancel voice input (tap mic again or press ESC)
  - [ ] 3.7 Focus input field after voice transcription completes

- [ ] Task 4: Integrate voice input into Chat Input (AC: 1, 4)
  - [ ] 4.1 Update `src/components/ai/ChatInput.tsx` to use `useSpeechRecognition` hook
  - [ ] 4.2 Replace disabled mic button with functional `VoiceInputButton`
  - [ ] 4.3 On voice result, populate input field with transcribed text (do NOT auto-submit)
  - [ ] 4.4 Show interim transcript with visual differentiation
  - [ ] 4.5 User can edit transcribed text before submitting
  - [ ] 4.6 User can cancel voice input (tap mic again or press ESC)
  - [ ] 4.7 Focus input field after voice transcription completes

- [ ] Task 5: Implement error handling (AC: 6)
  - [ ] 5.1 Handle `not-allowed` error: "Microphone access denied. Please enable in browser settings."
  - [ ] 5.2 Handle `no-speech` error: "No speech detected. Please try again."
  - [ ] 5.3 Handle `audio-capture` error: "No microphone found. Please check your device."
  - [ ] 5.4 Handle `network` error: "Network error. Voice input requires an internet connection."
  - [ ] 5.5 Handle `aborted` error: silently ignore (user cancelled)
  - [ ] 5.6 Handle unknown errors: "Voice input failed. Please try typing instead."
  - [ ] 5.7 Display errors inline below input (same pattern as chat errors)
  - [ ] 5.8 Auto-dismiss error after 5 seconds or on user interaction
  - [ ] 5.9 Provide "Try again" action in error state

- [ ] Task 6: Handle browser compatibility (AC: 5, 6)
  - [ ] 6.1 Create `src/lib/speechSupport.ts` with browser detection utilities
  - [ ] 6.2 Check for `SpeechRecognition` or `webkitSpeechRecognition` API
  - [ ] 6.3 If unsupported, hide mic button OR show disabled with tooltip
  - [ ] 6.4 Document supported browsers in code comments: Chrome, Edge, Safari (with limitations)
  - [ ] 6.5 Log unsupported browser to console (development only) for debugging

- [ ] Task 7: Write component tests (AC: 1-6)
  - [ ] 7.1 Create `src/__tests__/hooks/useSpeechRecognition.test.tsx`
  - [ ] 7.2 Create `src/__tests__/components/VoiceInputButton.test.tsx`
  - [ ] 7.3 Update `src/__tests__/components/AIBar.test.tsx` with voice tests
  - [ ] 7.4 Update `src/__tests__/components/ChatInput.test.tsx` with voice tests (if exists, else create)
  - [ ] 7.5 Test: Mic button starts speech recognition on click
  - [ ] 7.6 Test: Listening state shows pulsing animation
  - [ ] 7.7 Test: Transcribed text appears in input field
  - [ ] 7.8 Test: Interim transcript shows with reduced opacity
  - [ ] 7.9 Test: User can edit transcribed text before submit
  - [ ] 7.10 Test: Clicking mic again stops listening
  - [ ] 7.11 Test: ESC key cancels voice input
  - [ ] 7.12 Test: Error state displays error message
  - [ ] 7.13 Test: "Try again" button restarts recognition
  - [ ] 7.14 Test: Unsupported browser shows disabled button with tooltip
  - [ ] 7.15 Test: `prefers-reduced-motion` disables pulse animation
  - [ ] 7.16 Test: Focus moves to input after transcription complete
  - [ ] 7.17 Test: Voice input works in both AIBar and ChatInput

## Dev Notes

### Previous Story Context
[Source: Story 11.2 Implementation]

Story 11.2 implemented the AI Bar with text input and chat overlay/panel. The mic button is already present but disabled with tooltip "Voice input coming soon". This story enables that button.

**Key Files to Modify:**
- `web/src/components/layout/AIBar.tsx` — has disabled mic button
- `web/src/components/ai/ChatInput.tsx` — has disabled mic button in chat

**Existing Infrastructure:**
- `AIContext` for conversation state
- `useFindMatch` hook for AI queries
- Full-screen overlay (mobile) / slide-out panel (desktop) chat UI
- Error display pattern in chat messages

### Web Speech API Reference
[Source: Architecture v1 §2.4]

**Browser Support:**
- Chrome (desktop & Android): Full support
- Edge: Full support
- Safari (iOS & macOS): Supported with `webkitSpeechRecognition` prefix
- Firefox: NOT supported (user must type)

**API Interface:**
```typescript
// Check for support
const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;

// Create instance
const recognition = new SpeechRecognition();

// Configuration
recognition.continuous = false;     // Stop after one phrase
recognition.interimResults = true;  // Show partial results
recognition.lang = 'en-GB';         // British English

// Events
recognition.onstart = () => { /* listening started */ };
recognition.onresult = (event) => {
  const transcript = event.results[0][0].transcript;
  const isFinal = event.results[0].isFinal;
};
recognition.onerror = (event) => { /* event.error: string */ };
recognition.onend = () => { /* listening stopped */ };

// Control
recognition.start();
recognition.stop();
recognition.abort();
```

**Error Types:**
| Error | Meaning | User Action |
|-------|---------|-------------|
| `not-allowed` | Microphone permission denied | Guide to settings |
| `no-speech` | No speech detected | Suggest retry |
| `audio-capture` | No microphone | Check device |
| `network` | Network error | Check connection |
| `aborted` | Cancelled by user | Silent |
| `service-not-allowed` | Browser blocked | Use text input |

### Voice Input Button States
[Source: front-end-spec.md §5.8]

| State | Visual | Behavior |
|-------|--------|----------|
| Idle | Mic icon (`mic`) | Click to start listening |
| Listening | Pulsing mic with `--accent` glow | Click to stop, ESC to cancel |
| Processing | Mic with loading spinner | Transcribing... |
| Error | Mic-off icon (`mic-off`) | Show error, offer retry |
| Unsupported | Disabled mic (opacity 0.5) | Tooltip: "Not supported" |

**Pulsing Animation CSS:**
```css
@keyframes pulse-mic {
  0%, 100% {
    box-shadow: 0 0 0 0 rgba(59, 130, 246, 0.5);
  }
  50% {
    box-shadow: 0 0 0 8px rgba(59, 130, 246, 0);
  }
}

.listening {
  animation: pulse-mic 1.5s ease-in-out infinite;
}

@media (prefers-reduced-motion: reduce) {
  .listening {
    animation: none;
    box-shadow: 0 0 0 4px rgba(59, 130, 246, 0.3);
  }
}
```

### Interaction Flow
[Source: front-end-spec.md §4.2]

```
User taps mic → Recognition starts → "Listening..." visual
    ↓
User speaks → Interim transcript appears in input (grey/faded)
    ↓
User stops speaking → Final transcript appears (normal text)
    ↓
User reviews/edits → User taps Send OR presses Enter
    ↓
Query sent to AI (same as text input flow)
```

**Key UX Requirements:**
1. **Never auto-submit**: User must explicitly send (prevents mistakes)
2. **Always show transcript**: User can see what was heard
3. **Allow editing**: Transcription isn't perfect
4. **Clear cancel path**: Tap mic again or ESC

### Accessibility Requirements
[Source: front-end-spec.md §7.2]

**Voice Input Accessibility:**
- Visual feedback when listening (not audio-only) ✓
- Text review before sending ✓
- Alternative text input always available ✓

**Button Accessibility:**
- `aria-label="Start voice input"` (idle)
- `aria-label="Stop listening"` (listening)
- `aria-pressed="true"` when listening
- `aria-disabled="true"` when unsupported
- Announce state changes via `aria-live` region

### File Structure (Additions to 11.2)
```
web/src/
├── components/
│   ├── ai/
│   │   └── VoiceInputButton.tsx    # NEW - Voice button component
│   └── layout/
│       └── AIBar.tsx               # MODIFIED - Enable mic button
├── hooks/
│   └── useSpeechRecognition.ts     # NEW - Speech API hook
├── lib/
│   └── speechSupport.ts            # NEW - Browser detection
└── __tests__/
    ├── components/
    │   └── VoiceInputButton.test.tsx  # NEW
    └── hooks/
        └── useSpeechRecognition.test.tsx  # NEW
```

### Design System Reference
[Source: front-end-spec.md §6]

**Colors:**
- `--accent: #3B82F6` — Voice/AI interactive elements
- `--error: #EF4444` — Error states
- `--neutral-600: #4B5563` — Disabled/secondary text

**Animation:**
- Voice listening: Pulsing mic icon, continuous, ease-in-out
[Source: front-end-spec.md §9.2]

**Touch Targets:**
- Minimum 44x44px for voice button
[Source: front-end-spec.md §6.5]

### Safari-Specific Limitations
[Source: Web Speech API browser compatibility]

Safari (iOS & macOS) has known differences from Chrome/Edge:

| Behavior | Chrome/Edge | Safari |
|----------|-------------|--------|
| API Prefix | `SpeechRecognition` | `webkitSpeechRecognition` |
| Processing | Cloud-based (Google) | On-device |
| Network | Required | Not required |
| Timeout | ~60s before auto-stop | ~5-10s (shorter) |
| Continuous mode | Supported | Limited support |
| HTTPS | Required | Required |

**Implementation Notes:**
- Use shorter phrases on Safari (timeout is aggressive)
- Handle `no-speech` error more gracefully on Safari (more common)
- Safari may fire `onend` without `onerror` on timeout — treat as implicit `no-speech`
- Test on real iOS devices (Safari simulator behaves differently)

### Network Requirements

| Browser | Network Required | Reason |
|---------|------------------|--------|
| Chrome | Yes | Uses Google speech recognition servers |
| Edge | Yes | Uses Microsoft speech services |
| Safari | No | On-device processing |

**Offline Handling:**
- If user is offline on Chrome/Edge, speech recognition will fail with `network` error
- Show appropriate message: "Voice input requires an internet connection on this browser"
- Safari users can use voice input offline

### Language Configuration Rationale

The story specifies `lang: 'en-GB'` (British English) because:
1. **Target market:** UK amateur boxing clubs
2. **Terminology:** British boxing terms (e.g., "stone" for weight, regional club names)
3. **Consistency:** Matches locale of England Boxing rules and regulations

**Future consideration:** If FirstBell expands internationally, language selection could be added as a user preference. For MVP, hardcoded British English is appropriate.

### Mid-Session Permission Revocation

If user revokes microphone permission while listening:
1. Browser fires `onerror` with `not-allowed` error
2. Recognition stops automatically (`onend` fires)
3. Handle same as initial permission denial
4. Show message: "Microphone access denied. Please enable in browser settings."
5. Reset button to idle state
6. User can tap mic again to re-request permission

**Edge case:** Some browsers cache permission denial — user may need to manually reset in browser settings.

### Testing Considerations

**Mocking Web Speech API:**
```typescript
// Mock SpeechRecognition for tests
class MockSpeechRecognition {
  continuous = false;
  interimResults = true;
  lang = '';
  onstart: (() => void) | null = null;
  onresult: ((event: SpeechRecognitionEvent) => void) | null = null;
  onerror: ((event: SpeechRecognitionErrorEvent) => void) | null = null;
  onend: (() => void) | null = null;

  start() { this.onstart?.(); }
  stop() { this.onend?.(); }
  abort() { this.onend?.(); }
}

// In test setup
vi.stubGlobal('SpeechRecognition', MockSpeechRecognition);
```

**Testing Unsupported Browsers:**
```typescript
// Remove global to simulate unsupported browser
vi.stubGlobal('SpeechRecognition', undefined);
vi.stubGlobal('webkitSpeechRecognition', undefined);
```

## Testing

### Test File Locations
- `web/src/__tests__/hooks/useSpeechRecognition.test.tsx`
- `web/src/__tests__/components/VoiceInputButton.test.tsx`
- `web/src/__tests__/components/AIBar.test.tsx` (updated)
- `web/src/__tests__/components/ChatInput.test.tsx` (created or updated)

### Testing Framework
- Vitest + React Testing Library (from Story 11.1)
- Mock Web Speech API for unit tests

### Coverage Requirements
- All acceptance criteria must have corresponding tests
- Mock speech recognition for all unit tests
- Test all error states (permission denied, no speech, etc.)
- Test accessibility (aria attributes, focus management)
- Test reduced motion preference
- Minimum 13 test cases as listed in Task 7 (7.5-7.17)

---

## Change Log
| Date | Author | Change |
|------|--------|--------|
| 2026-01-13 | Sarah (PO) | Added Safari limitations, network requirements, language rationale, mid-session permission handling to Dev Notes. Validation score 9→10. |
| 2026-01-13 | Bob (SM) | Initial draft. Added AC6 for graceful degradation. Updated AC5 to include desktop support per user feedback. |

